{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import log\n",
        "from math import sqrt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n"
      ],
      "metadata": {
        "id": "KQUqI-pumDtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5UzOHFWeh0f"
      },
      "outputs": [],
      "source": [
        "subjects = []\n",
        "for i in range(1, 100):\n",
        "    file_name = f\"{i}\"\n",
        "    try:\n",
        "        with open(file_name) as file:\n",
        "            lines = file.readlines()\n",
        "            sub = None\n",
        "            for line in lines:\n",
        "                if line.strip():\n",
        "                    words = line.split(' ', 1)\n",
        "                    if words[0] == 'Subject:':\n",
        "                        sub = words[1].strip()\n",
        "                        break\n",
        "            if sub:\n",
        "                subjects.append(sub)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File {i} not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {i}: {str(e)}\")\n",
        "for i, subject in enumerate(subjects, 1):\n",
        "    print(f\"Subject of Email {i}: {subject}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def readAllEmails(path):\n",
        "    email_dic = {}\n",
        "    for filename in os.listdir(path):\n",
        "        with open(os.path.join(path, filename), 'r', encoding='utf-8') as file:\n",
        "            content = file.read()\n",
        "            subject = re.search(r'Subject: (.+)', content)\n",
        "            if subject:\n",
        "                subject = subject.group(1)\n",
        "                email_body = content.replace(f\"Subject: {subject}\", '')\n",
        "                email_dic[subject] = email_body\n",
        "    return email_dic"
      ],
      "metadata": {
        "id": "AoZL85ahmTdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getRandomSubject(email_dic):\n",
        "    return random.choice(list(email_dic.keys()))"
      ],
      "metadata": {
        "id": "BWG_1G6glchM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_lower(sample):\n",
        "    return sample.lower()\n",
        "def remove_stop_words(sample, stop_words):\n",
        "    words = sample.split()\n",
        "    filtered_words = [word for word in words if word not in stop_words]\n",
        "    return ' '.join(filtered_words)\n",
        "def normalize_data(sample, stop_words):\n",
        "    sample = to_lower(sample)\n",
        "    sample = remove_stop_words(sample, stop_words)\n",
        "    sample = re.sub(r'[\\[\\]\\(\\)\\.,;!?]', '', sample)\n",
        "    return sample\n",
        "def unique_words(sample):\n",
        "    words = sample.split()\n",
        "    return list(set(words))"
      ],
      "metadata": {
        "id": "WAxP1-z4lhvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bag_of_words(sample_list):\n",
        "    all_unique_words = set()\n",
        "    for sample in sample_list:\n",
        "        words = unique_words(sample)\n",
        "        all_unique_words.update(words)\n",
        "    return list(all_unique_words)\n",
        "def tf_idf(sample_list, bagOfWords):\n",
        "    D = len(sample_list)\n",
        "    w_ij = []\n",
        "    for i, sample in enumerate(sample_list):\n",
        "        words = sample.split()\n",
        "        tf_i = {word: words.count(word) / len(words) for word in bagOfWords}\n",
        "        df_i = {word: sum(1 for s in sample_list if word in s) for word in bagOfWords}\n",
        "        w_i = {word: tf_i[word] * math.log(D / df_i[word]) for word in bagOfWords}\n",
        "        w_ij.append(w_i)\n",
        "    return w_ij"
      ],
      "metadata": {
        "id": "OkdFPIT5lpm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_similarity(v1, v2):\n",
        "    dot_product = sum(x * y for x, y in zip(v1, v2))\n",
        "    magnitude_v1 = math.sqrt(sum(x ** 2 for x in v1))\n",
        "    magnitude_v2 = math.sqrt(sum(x ** 2 for x in v2))\n",
        "    if magnitude_v1 == 0 or magnitude_v2 == 0:\n",
        "        return 0.0\n",
        "    return dot_product / (magnitude_v1 * magnitude_v2)\n",
        "def rank(w_ij):\n",
        "    rank_dic = {}\n",
        "    for i in range(1, len(w_ij)):\n",
        "        similarity = cosine_similarity(w_ij[0], w_ij[i])\n",
        "        rank_dic[i] = similarity\n",
        "    return {k: v for k, v in sorted(rank_dic.items(), key=lambda item: item[1], reverse=True)}\n",
        "def show_result(rank_dic, n_mails, email_dic):\n",
        "    top_n = list(rank_dic.keys())[:n_mails]\n",
        "    subject = list(email_dic.keys())[0]\n",
        "    print(f\"Subject of email as: {subject} ...\")\n",
        "    for i in top_n:\n",
        "        print(f\"Email {i}: {list(email_dic.keys())[i]}\")"
      ],
      "metadata": {
        "id": "AfRyQ2nulums"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample1 = normalize_data(sample1, stop_words)\n",
        "sample2 = normalize_data(sample2, stop_words)\n",
        "line1 = normalize_data(line1, stop_words)\n",
        "line2 = normalize_data(line2, stop_words)\n",
        "\n",
        "sample_list = [sample1, sample2, line1]\n",
        "\n",
        "bow = bag_of_words(sample_list)\n",
        "\n",
        "w_ij = tf_idf(sample_list, bow)\n",
        "\n",
        "results = rank(w_ij)\n",
        "print(results)"
      ],
      "metadata": {
        "id": "WLIGXns_m5DP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}